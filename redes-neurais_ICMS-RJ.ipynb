{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f115bfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# State tax (ICMS) collection forecast using the LSTM (Long Short-Term Memory) recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9f905",
   "metadata": {},
   "source": [
    "### By Carlos Henrique C. Jr.\n",
    "### Rio de Janeiro, Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d68f6",
   "metadata": {},
   "source": [
    "Importação das bibliotecas Pandas e Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8632f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ff2e9",
   "metadata": {},
   "source": [
    "Carregamento da planilha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d32177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ICMS_1999-2023.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02254ed8",
   "metadata": {},
   "source": [
    "Média Móvel Simples dos últimos 12, 6, 3 e 2 períodos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMA(12)'] = df.ICMS.rolling(12).mean()\n",
    "df['SMA(6)'] = df.ICMS.rolling(6).mean()\n",
    "df['SMA(3)'] = df.ICMS.rolling(3).mean()\n",
    "df['SMA(2)'] = df.ICMS.rolling(2).mean()\n",
    "df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755659d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lag(12)'] = df.ICMS.shift(12)\n",
    "df['lag(6)'] = df.ICMS.shift(6)\n",
    "df['lag(4)'] = df.ICMS.shift(4)\n",
    "df['lag(3)'] = df.ICMS.shift(3)\n",
    "df['lag(2)'] = df.ICMS.shift(2)\n",
    "df['lag(1)'] = df.ICMS.shift(1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6c4e8",
   "metadata": {},
   "source": [
    "Importação da biblioteca Datetime, que fornece as classes para manipulação de datas e horas (para retornar o ordinal gregoriano proléptico de uma data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6568b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a409621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "df['DATA'] = df['DATA'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84cebc",
   "metadata": {},
   "source": [
    "Divisão da base de dados em uma base de treino, com os dados 75% iniciais, e uma base de testes com os 25% restantes, mais recentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01297965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = df.iloc[:train_size], df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['ICMS'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e589f347",
   "metadata": {},
   "source": [
    "Importação da Matplotlib, biblioteca Python de plotagem 2d, que auxilia a biblioteca matemática NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8267434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "plt.plot(train_dataset.ICMS)\n",
    "plt.plot(test_dataset.ICMS)\n",
    "plt.xlabel('Mês')\n",
    "plt.ylabel('ICMS')\n",
    "plt.legend(['Treino', 'Teste'], loc = 'upper left')\n",
    "print('Dimensão do dado de treino: ', train_dataset.shape)\n",
    "print('Dimensão do dado de teste: ', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b7611",
   "metadata": {},
   "source": [
    "Por volta do mês 255, que equivale a abril, maio, junho e julho de 2020, percebe-se uma queda expressiva de arrecadação de ICMS, depois de um pico sem precedentes em novembro de 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c2f11",
   "metadata": {},
   "source": [
    "Separação da variável dependente das independentes, tanto na base de treino, quanto na de testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7694be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop('ICMS', axis = 1)\n",
    "y_train = train_dataset.loc[:, ['ICMS']]\n",
    "X_test = test_dataset.drop('ICMS', axis = 1)\n",
    "y_test = test_dataset.loc[:, ['ICMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72b179",
   "metadata": {},
   "source": [
    "Importação da ferramenta de pré-processamento de dados MinMaxScaler da biblioteca scikit-learn. O MinMaxScaler dimensiona e traduz cada característica individualmente de modo que esteja na faixa dada no conjunto de treinamento, entre zero e um. Essa transformação é útil porque muitos algoritmos de aprendizado de máquina funcionam melhor quando os dados estão em uma escala comum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2acfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = scaler_x.fit(X_train)\n",
    "output_scaler = scaler_y.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97027cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_norm = output_scaler.transform(y_train)\n",
    "train_x_norm = input_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_norm = output_scaler.transform(y_test)\n",
    "test_x_norm = input_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_y_norm.shape: ', train_y_norm.shape)\n",
    "print('train_x_norm.shape: ', train_x_norm.shape)\n",
    "print('test_y_norm.shape: ', test_y_norm.shape)\n",
    "print('test_x_norm.shape: ', test_x_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057100e3",
   "metadata": {},
   "source": [
    "Redimensionamento da matriz para três dimensões. Sempre deve ser fornecida uma matriz tridimensional como uma entrada para uma rede LSTM. A primeira dimensão representa o tamanho do lote, a segunda dimensão representa o número de etapas de tempo com que se está alimentando uma sequência e a terceira dimensão representa o número de unidades em uma sequência de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_x_norm.reshape(70, 1, 11)\n",
    "X_train = train_x_norm.reshape(209, 1, 11)\n",
    "y_test = test_y_norm.reshape(70, 1)\n",
    "y_train = train_y_norm.reshape(209, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1ac0a",
   "metadata": {},
   "source": [
    "Importação da TensorFlow, plataforma completa de código aberto para machine learning, além do numpy.mean, para computar média aritmética, numpy.std, para computar o desvio padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c85297",
   "metadata": {},
   "source": [
    "Ajuste do modelo com 32, 64 e 128 neurônios para verificação do mais adequado para a aplicação. É buscado o parâmetro que retorne o menor erro, com a menor variação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando e validando um modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, \n",
    "                                  input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    \n",
    "    # Ajustando a rede\n",
    "    model.fit(X_train, y_train, epochs = 100, validation_split = 0.2, \n",
    "             batch_size = 4, shuffle = False)\n",
    "    \n",
    "    # Validando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, batch_size = 4, verbose = 0)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # Resumindo média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m = np.mean(scores[i])\n",
    "        s = np.std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m , s))\n",
    "        \n",
    "    # Boxplot das pontuações \n",
    "    pyplot.boxplot(scores, labels = params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento \n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # Repetindo experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "        \n",
    "    # Resumindo resultados\n",
    "    summarize_results(all_scores, params)\n",
    "    \n",
    "# Rodando o experimento\n",
    "n_params = [32, 64, 128]\n",
    "run_experiment(n_params)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando e validando um modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, \n",
    "                                  input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    \n",
    "    # Ajustando a rede\n",
    "    model.fit(X_train, y_train, epochs = 50, validation_split = 0.2, batch_size = 4, shuffle = False)\n",
    "    \n",
    "    # Validando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, batch_size = 4, verbose = 0)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    \n",
    "    # Resumindo média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "        \n",
    "    # Boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels = params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # Repetindo experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "        \n",
    "    # Resumindo resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [10, 15, 20, 25, 30]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd9a80",
   "metadata": {},
   "source": [
    "Ajuste de modelo com Tamanho do Lote 1, 2, 3, 4, 5, 6, 7 e 8 para verificação do mais adequado para a aplicação. Tamanho do lote (Batch Size) é um termo usado em aprendizado de máquina e refere-se ao número de exemplos de treinamento usados em iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c067fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando e validando um modelo\n",
    "\n",
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 32, return_sequences = True, \n",
    "                                   input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = 32))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    # Ajustando a rede\n",
    "    model.fit(X_train, y_train, epochs = 50, validation_split = 0.2, batch_size = batch_size, shuffle = False)\n",
    "    # Validando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 0)\n",
    "    return loss\n",
    "\n",
    "#Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # Resumindo média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "        \n",
    "    # Boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels = params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # Repetindo experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "        \n",
    "    # Resumindo resultados\n",
    "    summarize_results(all_scores, params)\n",
    "    \n",
    "# Rodando o experimento\n",
    "n_params = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdb90a",
   "metadata": {},
   "source": [
    "Ajuste de modelo com diluição (Dropout) 0.05, 0.1, 0.2, 0.3 para verificação do mais adequado para a aplicação. A diluição é uma técnica de regularização para reduzir o sobreajuste em redes neurais artificiais, impedindo co-adaptações complexas nos dados de treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 32, return_sequences = True, \n",
    "                                   input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = 32))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    # Ajustando a rede\n",
    "    model.fit(X_train, y_train, epochs = 50, validation_split = 0.2, batch_size = 1, shuffle = False)\n",
    "    # Validando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, batch_size = 1, verbose = 0)\n",
    "    return loss\n",
    "\n",
    "#Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # Resumindo média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "        \n",
    "    # Boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels = params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # Repetindo experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "        \n",
    "    # Resumindo resultados\n",
    "    summarize_results(all_scores, params)\n",
    "    \n",
    "# Rodando o experimento\n",
    "n_params = [0.05, 0.1, 0.2, 0.3]\n",
    "run_experiment(n_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146417c",
   "metadata": {},
   "source": [
    "Ajuste do modelo com os parâmetros mais adequados nos testes anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 32, return_sequences = True, \n",
    "                                   input_shape = [X_train.shape[1], \n",
    "                                                X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(0.05))\n",
    "    model.add(tf.keras.layers.LSTM(units = 32))\n",
    "    model.add(tf.keras.layers.Dropout(0.05))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    # Ajustando a rede\n",
    "    model.fit(X_train, y_train, epochs = 150, validation_split = 0.2, \n",
    "             batch_size = 1, shuffle = False)\n",
    "    \n",
    "    # Validando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, batch_size = 1, verbose = 0)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações \n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Loss: %.3f%% (+/-%.3f)' % (m, s))\n",
    "    \n",
    "# Rodando um experimento \n",
    "def run_experiment(repeats = 10):\n",
    "    # Repetindo o experimento\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score\n",
    "        print('>#%d: %.3f' % (r + 1, score))\n",
    "        scores.append(score)\n",
    "        \n",
    "    # Resumindo os resultados\n",
    "    summarize_results(scores)\n",
    "    \n",
    "# Rodando o experimento\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = units, return_sequences = True, input_shape = \n",
    "                                   [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = units))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe28627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = create_model(32, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1794bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "    history = model.fit(X_train, y_train, epochs = 150, \n",
    "                        validation_split = 0.2, batch_size = 1, shuffle = False, callbacks = [early_stop])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a00ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm = fit_model(model_lstm)\n",
    "model_lstm.save('TCC-MBA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e1228",
   "metadata": {},
   "source": [
    "Salvamento do modelo para posterior uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.load_model('TCC-MBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "y_train = scaler_y.inverse_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ae515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    prediction = model.predict(X_test)\n",
    "    prediction = scaler_y.inverse_transform(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y_test):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label = 'True Future')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction), label = 'Prediction')\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.xlabel('Mês')\n",
    "    plt.ylabel('ICMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_future(prediction_lstm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108964fd",
   "metadata": {},
   "source": [
    "Cálculo do Erro Médio Absoluto e Raiz Quadrática Média:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80530c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, actual, model_name):\n",
    "    errors = predictions - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
    "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prediction(prediction_lstm, y_test, 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a16302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "798d2d44",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados e aplicação do modelo em toda a base de dados (treino + teste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739896aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('ICMS', axis = 1)\n",
    "y = df.loc[:, ['ICMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = output_scaler.transform(y)\n",
    "x_norm = input_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_norm.reshape(279, 1, 11)\n",
    "y = y_norm.reshape(279, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scaler_y.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35771caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    prediction = model.predict(X)\n",
    "    prediction = scaler_y.inverse_transform(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y), label = 'Real')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction), label = 'Previsto')\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.xlabel('Mês')\n",
    "    plt.ylabel('ICMS-RJ (Bilhões de Reais), 1999-2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703061ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_future(prediction_lstm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78913a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = y.flatten()\n",
    "previsto = prediction_lstm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = pd.DataFrame([real, previsto]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4469d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = tabela.rename(columns={0: \"Real\", 1: \"Previsto\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela['Diferença'] = 1 - (tabela['Real'] / tabela['Previsto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13dfa96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tabela['Diferença'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a997d",
   "metadata": {},
   "source": [
    "Distribuição dos erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(data = tabela, x = \"Diferença\", kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ee976",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adddff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo = 1 # períodos adiante\n",
    "for i in range(periodo):\n",
    "    row = pd.DataFrame([], columns = previsao.columns)\n",
    "    row.loc[0, 'SMA(12)'] = previsao.ICMS.iloc[-12:].mean()\n",
    "    row.loc[0, 'SMA(6)'] = previsao.ICMS.iloc[-6:].mean()\n",
    "    row.loc[0, 'SMA(3)'] = previsao.ICMS.iloc[-3:].mean()\n",
    "    row.loc[0, 'SMA(2)'] = previsao.ICMS.iloc[-2:].mean()\n",
    "    row.loc[0, 'lag(12)'] = previsao.ICMS.iloc[-12]\n",
    "    row.loc[0, 'lag(6)'] = previsao.ICMS.iloc[-6]\n",
    "    row.loc[0, 'lag(4)'] = previsao.ICMS.iloc[-4]\n",
    "    row.loc[0, 'lag(3)'] = previsao.ICMS.iloc[-3]\n",
    "    row.loc[0, 'lag(2)'] = previsao.ICMS.iloc[-2]\n",
    "    row.loc[0, 'lag(1)'] = previsao.ICMS.iloc[-1]\n",
    "    row.loc[0, 'DATA'] = previsao.DATA.iloc[-1]+1\n",
    "    row = row.drop(['ICMS'], axis = 1)\n",
    "    row = np.array(row.iloc[-1]).reshape(1, -1)\n",
    "    row_norm = input_scaler.transform(row)\n",
    "    to_prev = row_norm.reshape(1, 1, 11)\n",
    "    prev = model_lstm.predict(to_prev)\n",
    "    prev = scaler_y.inverse_transform(prev)\n",
    "    row_ = pd.DataFrame(row, columns = ['DATA', 'SMA(12)', 'SMA(6)', 'SMA(3)', \n",
    "                                        'SMA(2)', 'lag(12)',  'lag(6)', 'lag(4)', \n",
    "                                        'lag(3)', 'lag(2)', 'lag(1)'])\n",
    "    row_.loc[0, 'ICMS'] = prev[0]\n",
    "    previsao = previsao.append(row_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter nbconvert --to slides presentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1b927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
